apiVersion: v1
data:
  _example: |
    ################################
    #                              #
    #    EXAMPLE CONFIGURATION     #
    #                              #
    ################################

    # This block is not actually functional configuration,
    # but serves to illustrate the available configuration
    # options and document them in a way that is accessible
    # to users that `kubectl edit` this config map.
    #
    # These sample configuration options may be copied out of
    # this example block and unindented to be in the data block
    # to actually change the configuration.

    # metrics.backend-destination field specifies the system metrics destination.
    # It supports either prometheus (the default) or stackdriver.
    # Note: Using stackdriver will incur additional charges
    metrics.backend-destination: prometheus

    # metrics.request-metrics-backend-destination specifies the request metrics
    # destination. If non-empty, it enables queue proxy to send request metrics.
    # Currently supported values: prometheus, stackdriver.
    metrics.request-metrics-backend-destination: prometheus

    # metrics.stackdriver-project-id field specifies the stackdriver project ID. This
    # field is optional. When running on GCE, application default credentials will be
    # used if this field is not provided.
    metrics.stackdriver-project-id: "<your stackdriver project id>"

    # metrics.allow-stackdriver-custom-metrics indicates whether it is allowed to send metrics to
    # Stackdriver using "global" resource type and custom metric type if the
    # metrics are not supported by "knative_broker", "knative_trigger", and "knative_source" resource types.
    # Setting this flag to "true" could cause extra Stackdriver charge.
    # If metrics.backend-destination is not Stackdriver, this is ignored.
    metrics.allow-stackdriver-custom-metrics: "false"

    # profiling.enable indicates whether it is allowed to retrieve runtime profiling data from
    # the pods via an HTTP server in the format expected by the pprof visualization tool. When
    # enabled, the Knative Eventing pods expose the profiling data on an alternate HTTP port 8008.
    # The HTTP context root for profiling is then /debug/pprof/.
    profiling.enable: "false"
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: knative-eventing-install
    app.kubernetes.io/name: knative-eventing-install
    eventing.knative.dev/release: v0.14.2
    knative.dev/config-category: eventing
    knative.dev/config-propagation: original
    kustomize.component: knative
  name: config-observability
  namespace: knative-eventing
