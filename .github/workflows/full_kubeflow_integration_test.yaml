name: Full Kubeflow Integration Test

on:
  workflow_dispatch: 
  push:
    branches:
      - master
  pull_request:
    branches:
      - master

jobs:
  build:
    name: Full E2E Integration Test
    runs-on:
      labels: ubuntu-latest-16-cores
    env:
      KIND_CLUSTER_NAME: kubeflow

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
        
    - name: Install Python dependencies
      run: |
        pip install pytest kubernetes kfp==2.11.0 kserve pytest-timeout pyyaml requests

    # Setup cluster and infrastructure 
    - name: Install KinD, Create KinD cluster and Install kustomize
      run: ./tests/gh-actions/install_KinD_create_KinD_cluster_install_kustomize.sh

    - name: Install kubectl
      run: ./tests/gh-actions/install_kubectl.sh

    - name: Install Trivy
      run: ./tests/gh-actions/install_trivy.sh

    - name: Create kubeflow namespace
      run: kustomize build common/kubeflow-namespace/base | kubectl apply -f -

    - name: Install Cert Manager
      run: ./tests/gh-actions/install_cert_manager.sh

    - name: Install Istio
      run: ./tests/gh-actions/install_istio.sh

    - name: Install oauth2-proxy
      run: ./tests/gh-actions/install_oauth2-proxy.sh

    # Main Kubeflow installation
    - name: Deploy Full Kubeflow Stack
      run: |
        # Apply with retry logic using exact command from README
        echo "Installing full Kubeflow stack from example/kustomization.yaml"
        while ! kustomize build example | kubectl apply --server-side --force-conflicts -f -; do 
          echo "Retrying to apply resources"; 
          sleep 20; 
        done
        
        # Wait for Kubeflow deployments to be ready
        echo "Waiting for Kubeflow deployments to be ready..."
        kubectl wait --for=condition=available --timeout=1800s deployment --all -n kubeflow || true
        
        # Check deployment status
        kubectl get deployments --all-namespaces
        kubectl get pods --all-namespaces

    - name: Install kubeflow-istio-resources
      run: kustomize build common/istio-1-24/kubeflow-istio-resources/base | kubectl apply -f -

    - name: Install KF Multi Tenancy
      run: ./tests/gh-actions/install_multi_tenancy.sh

    # Create user profile using existing script
    - name: Create KF Profile
      run: kustomize build common/user-namespace/base | kubectl apply -f -

    - name: Verify Profile Setup
      run: |
        # Wait for profile to be ready
        sleep 60
        
        # Verify profile resources
        KF_PROFILE=kubeflow-user-example-com
        kubectl -n $KF_PROFILE get pods,configmaps,secrets
        
        # Verify minio secret exists
        if ! kubectl get secret mlpipeline-minio-artifact -n $KF_PROFILE > /dev/null 2>&1; then
          echo "Error: Secret mlpipeline-minio-artifact not found in namespace $KF_PROFILE"
          exit 1
        fi

    - name: Install KNative (if needed)
      if: always()
      continue-on-error: true
      run: |
        # Check if KNative is required (it's in the kustomization.yaml)
        if grep -q "knative" example/kustomization.yaml; then
          echo "KNative detected in kustomization, installing..."
          if [ -f "tests/gh-actions/install_knative.sh" ]; then
            ./tests/gh-actions/install_knative.sh
          elif [ -f "tests/gh-actions/install_knative-cni.sh" ]; then
            ./tests/gh-actions/install_knative-cni.sh
          fi
        else
          echo "KNative not required, skipping installation"
        fi

    - name: Port Forward Istio Gateway
      run: |
        ingress_gateway_service=$(kubectl get svc --namespace istio-system --selector="app=istio-ingressgateway" --output jsonpath='{.items[0].metadata.name}')
        nohup kubectl port-forward --namespace istio-system svc/${ingress_gateway_service} 8080:80 &
        while ! curl localhost:8080; do echo waiting for port-forwarding; sleep 1; done; echo port-forwarding ready

    # Security scanning with Trivy
    - name: Run Trivy Security Scan
      if: always()
      continue-on-error: true
      run: |
        if command -v trivy &> /dev/null; then
          echo "Running Trivy security scans on critical images..."
          if [ -f "tests/gh-actions/trivy_scan.py" ]; then
            python3 tests/gh-actions/trivy_scan.py || true
          else
            # Fallback to basic image scan
            trivy image gcr.io/kubeflow-images-public/centraldashboard || true
          fi
        else
          echo "Trivy not installed properly, skipping security scan"
        fi

    # Authentication Tests
    - name: Test Auth Integration
      if: always()
      continue-on-error: true
      run: |
        # Use the Dex login test script directly
        if [ -f "tests/gh-actions/test_dex_login.py" ]; then
          echo "Running Dex login test..."
          python3 tests/gh-actions/test_dex_login.py
        else
          # Fallback to simple auth testing
          echo "Testing authentication redirect..."
          HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8080/pipeline/)
          if [[ $HTTP_STATUS -eq 302 || $HTTP_STATUS -eq 401 ]]; then
            echo "Auth check successful: Got redirect or unauthorized as expected"
          else
            echo "Warning: Expected auth redirect, got HTTP status $HTTP_STATUS"
          fi
        fi

    # Pipeline Tests 
    - name: Run Pipeline Tests
      run: |
        KF_PROFILE=kubeflow-user-example-com
        
        # Test with authorized token
        TOKEN="$(kubectl -n $KF_PROFILE create token default-editor)"
        echo "Running pipeline with authorized token"
        python3 tests/gh-actions/pipeline_test.py run_pipeline "${TOKEN}" "${KF_PROFILE}"
        
        # Test with unauthorized token
        echo "Testing unauthorized access"
        TOKEN="$(kubectl -n default create token default)"
        python3 tests/gh-actions/pipeline_test.py test_unauthorized_access "${TOKEN}" "${KF_PROFILE}"

    # Test Web UI components with basic connectivity checks
    - name: Test Central Dashboard Access
      run: |
        # Test central dashboard is accessible
        curl -I http://localhost:8080/
        
        # Check other components
        echo "Checking Notebooks access"
        curl -I http://localhost:8080/jupyter/
        
        echo "Checking Pipelines access"
        curl -I http://localhost:8080/pipeline/
        
        echo "Checking KServe access"
        curl -I http://localhost:8080/models/
        
        echo "Checking Katib access"
        curl -I http://localhost:8080/katib/

    # Notebook Tests 
    - name: Apply PodDefaults for Notebooks
      run: kubectl apply -f tests/gh-actions/kf-objects/poddefaults.access-ml-pipeline.kubeflow-user-example-com.yaml

    - name: Create Notebook Test
      if: always()
      run: |
        # Apply the notebook directly from tests
        kubectl apply -f tests/gh-actions/kf-objects/notebook.test.kubeflow-user-example.com.yaml
        
        # Wait for notebook to be ready - using exact syntax from pipeline_run_from_notebook.yaml
        kubectl wait --for=jsonpath='{.status.readyReplicas}'=1 \
          -f tests/gh-actions/kf-objects/notebook.test.kubeflow-user-example.com.yaml \
          --timeout 600s

    # Run Pipeline from Notebook 
    - name: Run Pipeline from Notebook
      if: always()
      continue-on-error: true
      run: |
        # Execute exactly as in pipeline_run_from_notebook.yaml
        KF_PROFILE=kubeflow-user-example-com
        if [ -f "tests/gh-actions/run_and_wait_kubeflow_pipeline.py" ]; then
          kubectl -n $KF_PROFILE cp \
            ./tests/gh-actions/run_and_wait_kubeflow_pipeline.py \
            test-0:/home/jovyan/run_and_wait_kubeflow_pipeline.py
  
          kubectl -n $KF_PROFILE exec -ti \
            test-0 -- python /home/jovyan/run_and_wait_kubeflow_pipeline.py
        else
          echo "Skipping pipeline run from notebook test - script not found"
        fi

    # Test Katib Experiments
    - name: Test Katib Experiment
      if: always()
      continue-on-error: true
      run: |
        # Apply Katib test directly from tests directory
        if kubectl get crd experiments.kubeflow.org > /dev/null 2>&1; then
          KF_PROFILE=kubeflow-user-example-com
          sed "s/kubeflow-user/$KF_PROFILE/g" tests/gh-actions/kf-objects/katib_test.yaml | kubectl apply -f - || echo "Katib experiment creation failed, continuing"
          kubectl get experiments -n ${KF_PROFILE}
        else
          echo "Katib CRD not found, skipping Katib tests"
        fi

    # Test Training Operator 
    - name: Test Training Operator
      if: always()
      continue-on-error: true
      run: |
        # Install Training Operator if needed
        if ! kubectl get crd tfjobs.kubeflow.org > /dev/null 2>&1; then
          ./tests/gh-actions/install_training_operator.sh
        fi
        
        # Apply the PyTorch job YAML directly
        if kubectl get crd pytorchjobs.kubeflow.org > /dev/null 2>&1; then
          KF_PROFILE=kubeflow-user-example-com
          sed "s/namespace: .*/namespace: $KF_PROFILE/g" tests/gh-actions/kf-objects/training_operator_job.yaml | kubectl apply -f -
          kubectl get pytorchjobs -n ${KF_PROFILE}
        else
          echo "Training Operator CRDs not found, skipping Training Operator tests"
        fi

    # Test KServe 
    - name: Test KServe Model Deployment
      if: always()
      continue-on-error: true
      run: |
        # Install KServe if needed using the script from tests directory
        if ! kubectl get crd inferenceservices.serving.kserve.io > /dev/null 2>&1; then
          ./tests/gh-actions/install_kserve.sh
        fi
        
        # Apply the KServe test directly
        if kubectl get crd inferenceservices.serving.kserve.io > /dev/null 2>&1; then
          KF_PROFILE=kubeflow-user-example-com
          sed -e "/metadata:/a\\  namespace: $KF_PROFILE" tests/gh-actions/kf-objects/kserve_test.yaml | kubectl apply -f -
          kubectl wait --for=condition=ready --timeout=120s -n ${KF_PROFILE} isvc/sklearn-iris || echo "InferenceService not ready"
        else
          echo "KServe CRD not found, skipping KServe tests"
        fi

    # Test Spark 
    - name: Test Spark Integration
      if: always()
      continue-on-error: true
      run: |
        if [ -f "tests/gh-actions/spark_install.sh" ] && [ -f "tests/gh-actions/spark_test.sh" ]; then
          KF_PROFILE=kubeflow-user-example-com
          chmod u+x tests/gh-actions/spark_*.sh
          ./tests/gh-actions/spark_install.sh
          ./tests/gh-actions/spark_test.sh "${KF_PROFILE}"
        else
          echo "Skipping Spark tests - scripts not found"
        fi

    # Test Pod Security Standards 
    - name: Test Pod Security Standards
      if: always()
      continue-on-error: true
      run: |
        # Apply baseline PSS using script from tests
        ./tests/gh-actions/enable_baseline_PSS.sh
        
        # Verify pods
        kubectl get pods --all-namespaces
        
        # Unapply baseline labels - following exact pattern from other workflows
        NAMESPACES=("istio-system" "auth" "cert-manager" "oauth2-proxy" "kubeflow" "knative-serving")
        for NAMESPACE in "${NAMESPACES[@]}"; do
          if kubectl get namespace "$NAMESPACE" >/dev/null 2>&1; then
            kubectl label namespace $NAMESPACE pod-security.kubernetes.io/enforce-
          fi
        done
        
        # Apply restricted PSS using script from tests
        ./tests/gh-actions/enable_restricted_PSS.sh
        
        # Verify pods still work
        kubectl get pods --all-namespaces

    # Final verification 
    - name: Verify All Components Running
      run: |
        # Run tests/gh-actions/runasnonroot.sh if available to validate security settings
        if [ -f "tests/gh-actions/runasnonroot.sh" ]; then
          echo "Running non-root security tests..."
          chmod +x tests/gh-actions/runasnonroot.sh
          ./tests/gh-actions/runasnonroot.sh || true
        fi
        
        # Verify all components are running
        echo "Checking critical components..."
        kubectl get deployment -n kubeflow
        kubectl get deployment -n cert-manager
        kubectl get deployment -n istio-system
        kubectl get deployment -n auth
        
        # Check for failed pods
        if kubectl get pods --all-namespaces | grep -E '(Error|CrashLoopBackOff)'; then
          echo "Found pods in failed state"
          exit 1
        fi
        
        echo "All Kubeflow components are running successfully"

    # Collect logs for debugging 
    - name: Collect Logs on Failure
      if: failure()
      run: |
        mkdir -p logs
        
        # Collect resource status
        kubectl get all --all-namespaces > logs/all-resources.txt
        kubectl get events --all-namespaces --sort-by=.metadata.creationTimestamp > logs/all-events.txt
        
        # Collect CRD status
        kubectl get crds | grep -E 'kubeflow|istio|knative|cert-manager|kserve' > logs/crds.txt || true
        
        # Collect pod descriptions
        namespaces=("kubeflow" "istio-system" "cert-manager" "auth")
        for ns in "${namespaces[@]}"; do
          kubectl describe pods -n $ns > logs/$ns-pod-descriptions.txt
          
          # Collect logs for each pod in namespace
          for pod in $(kubectl get pods -n $ns -o jsonpath='{.items[*].metadata.name}'); do
            kubectl logs -n $ns $pod --tail=100 > logs/$ns-$pod.txt 2>&1 || true
          done
        done
        
        echo "Collected logs to logs/ directory"
        
    - name: Upload Logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: kubeflow-test-logs
        path: logs/
